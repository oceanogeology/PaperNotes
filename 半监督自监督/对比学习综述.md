# 对比学习综述

![image-20211231104721969](..\images\2021123101.png)

![image-20211231160814016](..\images\2021123118.png)

## 第一阶段：百花齐放

###### InstDisc (https://www.semanticscholar.org/paper/Unsupervised-Feature-Learning-via-Non-parametric-Wu-Xiong/155b7782dbd713982a4133df3aee7adfd0b6b304)

亮点：将class-wise监督推到极致，学习单一实例（*个体判别*）的特征表示。 首次提出Memory Bank。

步骤：batchsize为256（也就是256个正样本），CNN提取2048维特征，因为Imagenet数据集较大，映射到128低维度，然后用当前网络随机对4096个负样本（从Memory Bank随机抽取），之后用NCELoss计算损失.

实验设置：temperature=0.07, m=4096, 200epoch, init lr=0.03

![image-20211231110814761](..\images\2021123102)

###### InvaSpread (https://www.semanticscholar.org/paper/Unsupervised-Embedding-Learning-via-Invariant-and-Ye-Zhang/e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b)

亮点：数据增强

步骤：batchsize为256（也就是256个正样本），和InstDisc不一样的是，负样本是数据增强之后除去本身的其他图片（也就是（256-1）*2）

缺点：负样本太小，不利于作对比学习

![image-20211231112219081](..\images\2021123103.png)

###### CPC (https://www.semanticscholar.org/paper/Representation-Learning-with-Contrastive-Predictive-Oord-Li/b227f3e4c0dc96e5ac5426b85485a70f2175a205)

亮点：预测代理任务做对比学习

步骤：以音频为例，当前时刻以及前t-3次时刻的token编码得到特征，经过自回归（RNN、LSTM等）之后得到Ct，假设Ct足够好，可以表示前几时刻的信息，那么用Ct去预测后几个时刻也是可行的。将预测得到的后几个时刻的编码特征作为pred，真实的后几个时刻编码特征作为正样本对，随机选取音频得到的编码特征作为负样本对.

![image-20211231112748301](..\images\2021123104.png)

###### [CMC](https://arxiv.org/pdf/1906.05849.pdf) （https://www.semanticscholar.org/paper/Contrastive-Multiview-Coding-Tian-Krishnan/97f4d09175705be4677d675fa27e55defac44800）

思想：同一图片在多视觉，多模态下经过特征提取之后应该聚集，不同图片则远离. 蒸馏方式建立teacher和student，构造老师和学生之间的正负样本对，进行对比学习.

![image-20211231134509210](..\images\2021123105.png)

## 第二阶段：CV双雄

###### [MoCov1](https://arxiv.org/pdf/1911.05722.pdf) （https://www.semanticscholar.org/paper/Momentum-Contrast-for-Unsupervised-Visual-Learning-He-Fan/ec46830a4b275fd01d4de82bffcabe6da086128f）

亮点：可以看成是Instdis的改进工作：动量编码器、写作牛逼

[MoCov2](https://arxiv.org/pdf/2003.04297.pdf) : 借鉴SimCLR的方法，添加了以下几种tricks，提点不少.

![image-20211231144508549](..\images\2021123108.png)

###### [SimCLRv1](https://arxiv.org/pdf/2002.05709.pdf) （https://www.semanticscholar.org/paper/A-Simple-Framework-for-Contrastive-Learning-of-Chen-Kornblith/34733eaf66007516347a40ad5d9bbe1cc9dacb6b）

亮点：backbone提取特征之后，增加了projection head一层mlp和relu（训练时有，测试无），可以提点10个，这个在有监督上面做不到；更多的数据增强；

步骤：单图片多种数据增强方式，进入同一编码器，N（batchsize）个正样本，2（N-1）个负样本，得到特征h，再进行非线性操作g，得到特征z，再进行loss.

<img src="..\images\2021123106.png" alt="image-20211231142127777" style="zoom:33%;" />

数据增强：crop+color提点最多，其他可有可无.

<img src="..\images\2021123107.png" alt="image-20211231144002320" style="zoom:33%;" />

[SimCLRv2](https://arxiv.org/pdf/2006.10029.pdf) : 大的自监督训练出来的模型非常适合去做半监督学习

![image-20211231144945804](..\images\2021123109.png)

###### [SWaV](https://arxiv.org/pdf/2006.09882.pdf) (https://www.semanticscholar.org/paper/Unsupervised-Learning-of-Visual-Features-by-Cluster-Caron-Misra/10161d83d29fc968c4612c9e9e2b61a2fc25842e)

亮点：聚类对比学习 + Multi-crop(关注全局和局部特征)

步骤：利用3000个聚类中心取代原始对比学习中的负样本，将特征z投影到聚类中心上.

![image-20211231150000890](..\images\2021123110.png)

![image-20211231151036479](..\images\2021123111.png)

## 第三阶段：不用负样本

###### [ BYOL](https://arxiv.org/pdf/2006.07733.pdf) （https://www.semanticscholar.org/paper/Bootstrap-Your-Own-Latent%3A-A-New-Approach-to-Grill-Strub/38f93092ece8eee9771e61c1edaf11b1293cae1b）

亮点：引入moco的动量编码器，引入simclr的projector，用MSEloss而不用Infonceloss进行对比学习

![image-20211231153107365](..\images\2021123112.png)

![image-20211231154218362](..\images\2021123113.png)

###### [SimSiam](https://arxiv.org/pdf/2011.10566.pdf) (https://www.semanticscholar.org/paper/Exploring-Simple-Siamese-Representation-Learning-Chen-He/0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d)

亮点：总结性工作 + simsiam和mocov2在下游任务上表现最好

<img src="..\images\2021123114.png" alt="image-20211231155006764" style="zoom: 67%;" />

<img src="..\images\2021123115.png" alt="image-20211231155229610" style="zoom:67%;" />

## 第四阶段：基于Transformer

###### [MoCov3](https://arxiv.org/pdf/2104.02057.pdf) （https://www.semanticscholar.org/paper/An-Empirical-Study-of-Training-Self-Supervised-Chen-Xie/739ceacfafb1c4eaa17509351b647c773270b3ae）

亮点：moco和simsiam的合体，发现tokenization这一层冻住会使得训练更稳定，精度更好.

![image-20211231160225611](..\images\2021123116.png)

###### [DINO](https://arxiv.org/pdf/2104.14294.pdf) （https://www.semanticscholar.org/paper/Emerging-Properties-in-Self-Supervised-Vision-Caron-Touvron/ad4a0938c48e61b7827869e4ac3baffd0aefab35）

亮点： 提出centering利于ViT模型训练稳定.

![image-20211231160532333](..\images\2021123117.png)